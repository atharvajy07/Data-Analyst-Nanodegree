{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  This report is a compilation of the data wrangling steps followed by me for the wrangle and analyze project of the DAND programme offered by Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data Wrangling section of this project has been divided into three parts:\n",
    " - __Data Gathering__\n",
    " \n",
    " - __Data Assessing__\n",
    " \n",
    " - __Data Cleaning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The data was gathered from three major sources:__\n",
    " - __From the 'twitter_archive_enhanced' csv file provided by the course instructors.__\n",
    " - __Programmatically downloading the 'image_predictions.tsv' file from Udacity's servers.__\n",
    " - __Querying data from twitter using the twitter API 'tweepy' into a JSON file and importing the JSON file into the jupyter notebook.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Data Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - __After gathering the data from various sources, the data was assessed visually(using Microsoft Excel) and programmatically using several libraries like Pandas.__\n",
    " - __The dataset was found to be messy as well as dirty.__\n",
    " - __Several quality and tidiness issues were observed and documented.__\n",
    " - __The Quality issues found are as follow:__\n",
    "\n",
    "\n",
    " 1. The tweet_id column in the df_archive dataframe has the wrong data type and the values are in exponential format.\n",
    " - In df_archive, names like __'a','an', 'no'__ etc. which do not make any sense \n",
    " - In df_archive, timestamp should be of datetime datatype.\n",
    " - There are __5__ entries in table __a__ with name __very__ which does not sound logical and should be '__Avery__'\n",
    " - Column names - __'p1','p1_conf','p2','p2_conf','p3','p3_conf'__ in df_predare not intuitive. \n",
    " - The rows with a numerical value in the _'in_reply_to_status_id'_ are replies and not original tweets.\n",
    " - The rows with a numerical value in the _'retweeted_status_id\t'_ are retweets and not original tweets.\n",
    " - The row 'id' in df_tweepy is not synonymous to the corresponding rows in the tables a and b.\n",
    " - Some rows have denominator values other than 10 which is invalid.__\n",
    " - Some rows have numerator value less than 10 which is invalid.__\n",
    " \n",
    "\n",
    " - __The Tidiness issues found are as follows__:\n",
    "  1. The __'in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id'\t'retweeted_status_timestamp'__ are not useful for any analysis as we are considering data on only original tweets..\n",
    "  - The rating_denominator should have a unique value and thus the column can be dropped.Moreover, the rating_numerator can have a more intuitive name.\n",
    "  - The favorite_count column can have a more intuitive name.\n",
    "  - In df_archive, there are __745__ entries with value _NONE_ in the __name__ column.Mo\n",
    "  - The doggo,floofer,pupper and puppo contain values of a single column.\n",
    "\n",
    "\n",
    "## PS: \n",
    " - df_archive contains the data from the  'twitter_archive_enhanced' file.\n",
    " - df_pred  contains the data from the 'image_predictions.tsv' file.\n",
    " - df_tweepy contains the data queried from twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - __After identifying and documenting the quality and tidiness issues in the data, the data was extensively cleaned using several Python Libraries like pandas.__\n",
    " - __Each cleaning step was divided into three parts:__\n",
    "  1. __Define__: Defining the issue and how it will be fixed.\n",
    "  -  __Code__: Writing code to fix the issue.\n",
    "  -  __Test__: Testing to check whether the issue has been fixed.\n",
    " - __A total of seventeen cleaning steps were undertaken to fix the documented issues in the data.__\n",
    " - __After the fixing all the documented issues, the clean and tidy dataframes were exported and saved as csv files named__ -\n",
    "  1. df_archive: 'twitter_archive_master.csv'.\n",
    "  -  df_pred: 'predicted_dogs.csv'\n",
    "  -  df_tweepy: 'tweepy.csv'\n",
    " - __The Data Cleaning step was the final part of the Data Wrangling Section.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations:\n",
    "### Due to some error in the 'twitter_archive_enhanced.csv' file's twitter_id column, the three dataframes could not be merged into one and collective analysis on the dataset could not be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and visualization was carried out after the Data Wrangling section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
